{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = r\"D:\\SEM 4\\CS516\\516 Project\\src\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from data_loader import load_dataset\n",
    "from modeling import train_smote_forest, evaluate_model, train_random_forest\n",
    "from fairness_metrics import print_group_rates, disparate_impact, equal_opportunity\n",
    "from preprocess import apply_reweighing\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.metrics import MetricFrame, selection_rate\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_dataset(\"../data/cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a preprocessing mitigation strategy - AIF360â€™s Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Man' 'Woman' 'NonBinary']\n",
      "object\n",
      "['<35' '>35']\n",
      "object\n",
      "Index(['Gender_encoded', 'Age_encoded', 'YearsCode', 'YearsCodePro',\n",
      "       'ComputerSkills', 'PreviousSalary', 'Gender_group_NonBinary',\n",
      "       'Gender_group_Woman', 'Age_group_>35', 'EdLevel_NoHigherEd',\n",
      "       'EdLevel_Other', 'EdLevel_PhD', 'EdLevel_Undergraduate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Apply AIF360 Reweighing (only used for fairness metrics, not for training if SMOTE is applied)\n",
    "df = apply_reweighing(df, protected_attr='Gender', label_col='Employment')\n",
    "\n",
    "gender_map = {0: 'Man', 1: 'NonBinary', 2: 'Woman'}\n",
    "#age_map = {0: '<35', 1: '>35'}\n",
    "\n",
    "df['Gender_group'] = df['Gender'].map(gender_map)\n",
    "df['Age_group'] = df['Age']  \n",
    "\n",
    "\n",
    "print(df['Gender_group'].unique())\n",
    "print(df['Gender_group'].dtype)\n",
    "\n",
    "print(df['Age_group'].unique())\n",
    "print(df['Age_group'].dtype)\n",
    "\n",
    "\n",
    "# Step 2: Feature engineering for modeling\n",
    "features = [\n",
    "    'Gender_group', 'Age_group', 'EdLevel', 'Gender_encoded', 'Age_encoded',\n",
    "    'YearsCode', 'YearsCodePro', 'ComputerSkills', 'PreviousSalary'\n",
    "]\n",
    "X = pd.get_dummies(df[features], drop_first=True)\n",
    "y = df['Employment'].astype(int)\n",
    "\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8051181995553337\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.19      0.18      2571\n",
      "           1       0.89      0.89      0.89     19468\n",
      "\n",
      "    accuracy                           0.81     22039\n",
      "   macro avg       0.54      0.54      0.54     22039\n",
      "weighted avg       0.81      0.81      0.81     22039\n",
      "\n",
      "Pearson Correlation: 0.0743\n",
      "Mean Absolute Error: 0.1949\n",
      "Accuracy for Gender Man: 0.8001\n",
      "Accuracy for Gender NonBinary: 0.8318\n",
      "Accuracy for Gender Woman: 0.8947\n",
      "Equal Accuracy Gap: 0.0946\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Choose model strategy\n",
    "use_smote = True  # Toggle this to False to use reweighing instead of SMOTE\n",
    "\n",
    "if use_smote:\n",
    "    model, X_test, y_test, y_pred = train_smote_forest(X, y)\n",
    "else:\n",
    "    sample_weights = df['instance_weight']\n",
    "    model, X_test, y_test, y_pred = train_random_forest(X, y, sample_weights)\n",
    "\n",
    "# Step 4: Evaluate base model performance (before fairness post-processing)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n",
    "# --- 3. Equal Accuracy by Gender Group ---\n",
    "y_test_aligned = y_test.reset_index(drop=True)\n",
    "y_pred_aligned = pd.Series(y_pred).reset_index(drop=True)\n",
    "gender_column = df.loc[y_test.index, 'Gender_group'].reset_index(drop=True)\n",
    "\n",
    "# --- 1. Pearson's Correlation ---\n",
    "pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "print(f\"Pearson Correlation: {round(pearson_corr, 4)}\")\n",
    "\n",
    "# --- 2. Mean Absolute Error ---\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {round(mae, 4)}\")\n",
    "\n",
    "equal_accuracy = {}\n",
    "for group in sorted(gender_column.unique()):\n",
    "    group_mask = gender_column == group\n",
    "    acc = accuracy_score(y_test_aligned[group_mask], y_pred_aligned[group_mask])\n",
    "    equal_accuracy[group] = acc\n",
    "    print(f\"Accuracy for Gender {group}: {round(acc, 4)}\")\n",
    "\n",
    "equal_accuracy_gap = max(equal_accuracy.values()) - min(equal_accuracy.values())\n",
    "print(f\"Equal Accuracy Gap: {round(equal_accuracy_gap, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.89\n",
      "1: TPR = 0.89\n",
      "2: TPR = 0.87\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Custom fairness metrics based on fairness-aware predictions\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "# Disparate impact comparisons\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "# Equal opportunity using fairness-aware predictions\n",
    "equal_opportunity(\n",
    "    y_test.reset_index(drop=True),\n",
    "    pd.Series(y_pred), \n",
    "    [0, 1, 2],  # Man, NonBinary, Woman\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_consistent_metrics(y_test, y_pred, sensitive_col='Gender_encoded', label_name='Gender'):\n",
    "    \"\"\"\n",
    "    Evaluate predictions using MAE, Pearson correlation, and group-wise accuracy.\n",
    "    Assumes access to global df and X_test_pmute for index alignment.\n",
    "    \"\"\"\n",
    "    # Align predictions and labels\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "    \n",
    "    # Align sensitive attribute values from df using test indices\n",
    "    sensitive_series = df.loc[y_test.index, sensitive_col].reset_index(drop=True)\n",
    "\n",
    "    # --- 1. Pearson Correlation ---\n",
    "    pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "    print(f\"\\nPearson Correlation: {round(pearson_corr, 4)}\")\n",
    "\n",
    "    # --- 2. Mean Absolute Error ---\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {round(mae, 4)}\")\n",
    "\n",
    "    # --- 3. Group-wise Accuracy ---\n",
    "    print(f\"\\nAccuracy by {label_name} group:\")\n",
    "    for group in sorted(sensitive_series.unique()):\n",
    "        group_mask = sensitive_series == group\n",
    "        acc = accuracy_score(y_test[group_mask], y_pred[group_mask])\n",
    "        print(f\"{label_name} {group}: {round(acc, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient on SMOTE-balanced data:\n",
      "Accuracy: 0.516947229910613\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.54      0.21      2571\n",
      "           1       0.89      0.51      0.65     19468\n",
      "\n",
      "    accuracy                           0.52     22039\n",
      "   macro avg       0.51      0.53      0.43     22039\n",
      "weighted avg       0.80      0.52      0.60     22039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Prepare data: remove sensitive feature from X, pass separately ---\n",
    "sensitive_feature_test = df.loc[X_test.index, \"Gender_encoded\"]\n",
    "sensitive_feature_train = df.loc[X.index.difference(X_test.index), \"Gender_encoded\"]\n",
    "\n",
    "X_train_eg = X.loc[X.index.difference(X_test.index)].drop(columns=[\"Gender_encoded\"])\n",
    "y_train_eg = y.loc[X.index.difference(X_test.index)]\n",
    "\n",
    "X_test_eg = X_test.drop(columns=[\"Gender_encoded\"])\n",
    "\n",
    "# --- 2. Train fairness-aware model ---\n",
    "eg_model = ExponentiatedGradient(\n",
    "    estimator=LogisticRegression(solver=\"liblinear\", class_weight='balanced'),\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01\n",
    ")\n",
    "eg_model.fit(X_train_eg, y_train_eg, sensitive_features=sensitive_feature_train)\n",
    "\n",
    "# --- 3. Predict ---\n",
    "y_pred_eg = eg_model.predict(X_test_eg)\n",
    "\n",
    "# --- 4. Evaluate performance ---\n",
    "print(\"Exponentiated Gradient on SMOTE-balanced data:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_eg))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_eg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.516947229910613\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.54      0.21      2571\n",
      "           1       0.89      0.51      0.65     19468\n",
      "\n",
      "    accuracy                           0.52     22039\n",
      "   macro avg       0.51      0.53      0.43     22039\n",
      "weighted avg       0.80      0.52      0.60     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.0326\n",
      "Mean Absolute Error: 0.4831\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.5161\n",
      "Gender 1: 0.5665\n",
      "Gender 2: 0.5148\n",
      "\n",
      "Pearson Correlation: 0.0326\n",
      "Mean Absolute Error: 0.4831\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.5145\n",
      "Age 1: 0.5221\n",
      "\n",
      "Pearson Correlation: 0.0326\n",
      "Mean Absolute Error: 0.4831\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.5159\n",
      "EdLevel NoHigherEd: 0.5274\n",
      "EdLevel Other: 0.5097\n",
      "EdLevel PhD: 0.5078\n",
      "EdLevel Undergraduate: 0.5192\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Custom evaluation function (consistent with pre-processing) ---\n",
    "evaluate_model(y_test, y_pred_eg)\n",
    "\n",
    "# --- 6. Reusable consistency metrics: Pearson, MAE, group-wise accuracy ---\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='EdLevel', label_name='EdLevel')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.516294        0.507212\n",
      "1               0.523697        0.552133\n",
      "2               0.527290        0.515595\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.538333        0.541675\n",
      "1            0.476947        0.446340\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.516273        0.513770\n",
      "NoHigherEd     0.508676        0.516895\n",
      "Other          0.497835        0.470934\n",
      "PhD            0.508951        0.478261\n",
      "Undergraduate  0.524083        0.517819\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Group fairness metrics ---\n",
    "# Gender\n",
    "mf_eg_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=sensitive_feature_test\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender:\")\n",
    "print(mf_eg_gender.by_group)\n",
    "\n",
    "# Age\n",
    "mf_eg_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=df.loc[X_test.index, 'Age_encoded']\n",
    ")\n",
    "print(\"\\nFairness metrics by Age:\")\n",
    "print(mf_eg_age.by_group)\n",
    "\n",
    "# EdLevel\n",
    "mf_eg_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=df.loc[X_test.index, 'EdLevel']\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel:\")\n",
    "print(mf_eg_edlevel.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.51\n",
      "1: TPR = 0.57\n",
      "2: TPR = 0.51\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Custom fairness functions ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test.reset_index(drop=True),\n",
    "    pd.Series(y_pred_eg),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ThresholdOptimizer(constraints=&#x27;equalized_odds&#x27;,\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ThresholdOptimizer<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ThresholdOptimizer(constraints=&#x27;equalized_odds&#x27;,\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method=&#x27;predict_proba&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ThresholdOptimizer(constraints='equalized_odds',\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method='predict_proba')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. 3-Way Split: Train (60%), Validation (10%), Test (30%) ---\n",
    "X_trainval, X_test_post, y_trainval, y_test_post = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train_post, X_val_post, y_train_post, y_val_post = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Apply SMOTE to training data ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_post_smote, y_train_post_smote = smote.fit_resample(X_train_post, y_train_post)\n",
    "\n",
    "# --- 3. Train classifier on SMOTE-balanced data ---\n",
    "model_post = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_post.fit(X_train_post_smote, y_train_post_smote)\n",
    "\n",
    "# --- 4. Apply ThresholdOptimizer using validation set ---\n",
    "sensitive_gender_val = df.loc[X_val_post.index, \"Gender_encoded\"]\n",
    "\n",
    "postprocessor = ThresholdOptimizer(\n",
    "    estimator=model_post,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "\n",
    "postprocessor.fit(\n",
    "    X_val_post,\n",
    "    y_val_post,\n",
    "    sensitive_features=sensitive_gender_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness-aware Evaluation (SMOTE + Equalized Odds):\n",
      "Overall Accuracy: 0.8660556286582876\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.06      0.10      2576\n",
      "           1       0.89      0.97      0.93     19463\n",
      "\n",
      "    accuracy                           0.87     22039\n",
      "   macro avg       0.56      0.52      0.51     22039\n",
      "weighted avg       0.81      0.87      0.83     22039\n",
      "\n",
      "Accuracy: 0.8660556286582876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.06      0.10      2576\n",
      "           1       0.89      0.97      0.93     19463\n",
      "\n",
      "    accuracy                           0.87     22039\n",
      "   macro avg       0.56      0.52      0.51     22039\n",
      "weighted avg       0.81      0.87      0.83     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.0635\n",
      "Mean Absolute Error: 0.1339\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.865\n",
      "Gender 1: 0.8484\n",
      "Gender 2: 0.8996\n",
      "\n",
      "Pearson Correlation: 0.0635\n",
      "Mean Absolute Error: 0.1339\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.8644\n",
      "Age 1: 0.8695\n",
      "\n",
      "Pearson Correlation: 0.0635\n",
      "Mean Absolute Error: 0.1339\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.866\n",
      "EdLevel NoHigherEd: 0.8706\n",
      "EdLevel Other: 0.8727\n",
      "EdLevel PhD: 0.8777\n",
      "EdLevel Undergraduate: 0.8629\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Predict on test set ---\n",
    "sensitive_gender_test = df.loc[X_test_post.index, \"Gender_encoded\"]\n",
    "y_pred_fair = postprocessor.predict(\n",
    "    X_test_post,\n",
    "    sensitive_features=sensitive_gender_test\n",
    ")\n",
    "\n",
    "# --- 6. Evaluate overall performance ---\n",
    "print(\"\\nFairness-aware Evaluation (SMOTE + Equalized Odds):\")\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_test_post, y_pred_fair))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_post, y_pred_fair))\n",
    "\n",
    "# --- 7. Custom Evaluation ---\n",
    "evaluate_model(y_test_post, y_pred_fair)\n",
    "\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='EdLevel', label_name='EdLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.864945        0.968736\n",
      "1               0.861575        0.966587\n",
      "2               0.890304        0.962782\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.890317        0.981111\n",
      "1            0.821749        0.945242\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.873960        0.975217\n",
      "NoHigherEd     0.784710        0.936731\n",
      "Other          0.798713        0.927696\n",
      "PhD            0.879423        0.982962\n",
      "Undergraduate  0.888998        0.979065\n"
     ]
    }
   ],
   "source": [
    "# --- 8. MetricFrame Fairness Evaluation ---\n",
    "mf_post_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=sensitive_gender_test\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender:\")\n",
    "print(mf_post_gender.by_group)\n",
    "\n",
    "mf_post_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=df.loc[X_test_post.index, 'Age_encoded']\n",
    ")\n",
    "print(\"\\nFairness metrics by Age:\")\n",
    "print(mf_post_age.by_group)\n",
    "\n",
    "mf_post_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=df.loc[X_test_post.index, 'EdLevel']\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel:\")\n",
    "print(mf_post_edlevel.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.97\n",
      "1: TPR = 0.97\n",
      "2: TPR = 0.98\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Custom Fairness Metrics ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_post.reset_index(drop=True),\n",
    "    pd.Series(y_pred_fair),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Proxy Mute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14621b362384e4db80d1a9a773b01ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Train-Test Split ---\n",
    "X_train_pmute, X_test_pmute, y_train_pmute, y_test_pmute = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Train Base Model (Logistic Regression with Class Weights) ---\n",
    "lr_model_base = LogisticRegression(solver=\"liblinear\", class_weight='balanced')\n",
    "lr_model_base.fit(X_train_pmute, y_train_pmute)\n",
    "\n",
    "# --- 3. SHAP Explainability (KernelExplainer for probability output) ---\n",
    "explainer = shap.KernelExplainer(\n",
    "    lr_model_base.predict_proba,\n",
    "    X_train_pmute.sample(100, random_state=42)\n",
    ")\n",
    "shap_values = explainer.shap_values(X_test_pmute[:100])\n",
    "\n",
    "# --- 4. Mean Absolute SHAP Importance ---\n",
    "mean_abs_shap = np.abs(shap_values[1]).mean(axis=0)\n",
    "shap_summary = pd.DataFrame({\n",
    "    \"feature\": X_train_pmute.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProxyMute (Revised Proxy List):\n",
      "Accuracy: 0.6645038341122556\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.44      0.23      2576\n",
      "           1       0.90      0.69      0.79     19463\n",
      "\n",
      "    accuracy                           0.66     22039\n",
      "   macro avg       0.53      0.57      0.51     22039\n",
      "weighted avg       0.82      0.66      0.72     22039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Define Proxy Features to Mute (based on SHAP summary) ---\n",
    "proxy_features = ['PreviousSalary', 'EdLevel_Undergraduate', 'ComputerSkills']\n",
    "\n",
    "# --- 6. Muting Proxy Features in Test Set ---\n",
    "X_test_muted = X_test_pmute.copy()\n",
    "for col in proxy_features:\n",
    "    if col in X_test_muted.columns:\n",
    "        X_test_muted[col] = X_test_muted[col].mean()\n",
    "\n",
    "# --- 7. Predict on Muted Test Set ---\n",
    "y_pred_muted = lr_model_base.predict(X_test_muted)\n",
    "\n",
    "# --- 8. Performance Metrics ---\n",
    "print(\"ProxyMute (Revised Proxy List):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_pmute, y_pred_muted))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_pmute, y_pred_muted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender (ProxyMute SHAP):\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.656197        0.669013\n",
      "1               0.739857        0.749403\n",
      "2               0.801175        0.857982\n",
      "\n",
      "Fairness metrics by Age (ProxyMute SHAP):\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.873675        0.959553\n",
      "1            0.282508        0.167479\n",
      "\n",
      "Fairness metrics by EdLevel (ProxyMute SHAP):\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.663126        0.666313\n",
      "NoHigherEd     0.596661        0.630931\n",
      "Other          0.543199        0.537377\n",
      "PhD            0.595020        0.570118\n",
      "Undergraduate  0.712071        0.739421\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Fairness Evaluation Using MetricFrame ---\n",
    "# Gender\n",
    "mf_shap_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"Gender_encoded\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender (ProxyMute SHAP):\")\n",
    "print(mf_shap_gender.by_group)\n",
    "\n",
    "# Age\n",
    "mf_shap_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"Age_encoded\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by Age (ProxyMute SHAP):\")\n",
    "print(mf_shap_age.by_group)\n",
    "\n",
    "# EdLevel\n",
    "mf_shap_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"EdLevel\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel (ProxyMute SHAP):\")\n",
    "print(mf_shap_edlevel.by_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6645038341122556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.44      0.23      2576\n",
      "           1       0.90      0.69      0.79     19463\n",
      "\n",
      "    accuracy                           0.66     22039\n",
      "   macro avg       0.53      0.57      0.51     22039\n",
      "weighted avg       0.82      0.66      0.72     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.0904\n",
      "Mean Absolute Error: 0.3355\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.6652\n",
      "Gender 1: 0.6064\n",
      "Gender 2: 0.673\n",
      "\n",
      "Pearson Correlation: 0.0904\n",
      "Mean Absolute Error: 0.3355\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.6637\n",
      "Age 1: 0.6662\n",
      "\n",
      "Pearson Correlation: 0.0904\n",
      "Mean Absolute Error: 0.3355\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.6585\n",
      "EdLevel NoHigherEd: 0.6559\n",
      "EdLevel Other: 0.6643\n",
      "EdLevel PhD: 0.633\n",
      "EdLevel Undergraduate: 0.6704\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Consistent Utility Metrics ---\n",
    "evaluate_model(y_test_pmute, y_pred_muted)\n",
    "\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='EdLevel', label_name='EdLevel')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.70\n",
      "1: TPR = 0.64\n",
      "2: TPR = 0.69\n"
     ]
    }
   ],
   "source": [
    "# --- 11. Custom Fairness Metrics ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_pmute.reset_index(drop=True),\n",
    "    pd.Series(y_pred_muted),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Refined Proxy Mute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Initialize LIME Explainer ---\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_train_pmute.values,\n",
    "    feature_names=X_train_pmute.columns.tolist(),\n",
    "    class_names=[\"Not Employed\", \"Employed\"],\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=False\n",
    ")\n",
    "\n",
    "# --- 2. Local Muting: Top 2 Features per Instance ---\n",
    "X_test_localmute_muted = X_test_pmute.copy()\n",
    "\n",
    "for i in range(500):  # Apply LIME only to top 500 for speed\n",
    "    exp = explainer.explain_instance(\n",
    "        X_test_pmute.iloc[i].values,\n",
    "        lambda x: lr_model_base.predict_proba(pd.DataFrame(x, columns=X_train_pmute.columns)),\n",
    "        num_features=2\n",
    "    )\n",
    "    top_features = [f[0] for f in exp.as_list()]\n",
    "    \n",
    "    for f in top_features:\n",
    "        f_name = f.split('<')[0].split('>')[0].split('=')[0].strip()\n",
    "        if f_name in X_test_localmute_muted.columns:\n",
    "            col_idx = X_test_localmute_muted.columns.get_loc(f_name)\n",
    "            mean_val = X_train_pmute[f_name].mean()\n",
    "            col_dtype = X_test_localmute_muted.dtypes[f_name]\n",
    "            X_test_localmute_muted.iat[i, col_idx] = col_dtype.type(mean_val)\n",
    "\n",
    "# --- 3. Predict ---\n",
    "y_pred_lime_localmute = lr_model_base.predict(X_test_localmute_muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined ProxyMute (LIME, Top 2 Features):\n",
      "Accuracy: 0.6051544988429602\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.58      0.25      2576\n",
      "           1       0.92      0.61      0.73     19463\n",
      "\n",
      "    accuracy                           0.61     22039\n",
      "   macro avg       0.54      0.59      0.49     22039\n",
      "weighted avg       0.83      0.61      0.68     22039\n",
      "\n",
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.595466        0.574882\n",
      "1               0.625298        0.634845\n",
      "2               0.792360        0.811949\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.710343        0.725581\n",
      "1            0.413055        0.333932\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.485219        0.439193\n",
      "NoHigherEd     0.315466        0.161687\n",
      "Other          0.296569        0.174326\n",
      "PhD            0.557012        0.500655\n",
      "Undergraduate  0.787884        0.830379\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Performance Metrics ---\n",
    "print(\"Refined ProxyMute (LIME, Top 2 Features):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_pmute, y_pred_lime_localmute))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_pmute, y_pred_lime_localmute))\n",
    "\n",
    "# --- 5. Fairness: MetricFrame by Group ---\n",
    "for attr, label in [(\"Gender_encoded\", \"Gender\"), (\"Age_encoded\", \"Age\"), (\"EdLevel\", \"EdLevel\")]:\n",
    "    mf = MetricFrame(\n",
    "        metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "        y_true=y_test_pmute,\n",
    "        y_pred=y_pred_lime_localmute,\n",
    "        sensitive_features=df.loc[X_test_pmute.index, attr]\n",
    "    )\n",
    "    print(f\"\\nFairness metrics by {label}:\")\n",
    "    print(mf.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6051544988429602\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.58      0.25      2576\n",
      "           1       0.92      0.61      0.73     19463\n",
      "\n",
      "    accuracy                           0.61     22039\n",
      "   macro avg       0.54      0.59      0.49     22039\n",
      "weighted avg       0.83      0.61      0.68     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.1217\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.6055\n",
      "Gender 1: 0.5851\n",
      "Gender 2: 0.6057\n",
      "\n",
      "Pearson Correlation: 0.1217\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.6025\n",
      "Age 1: 0.6107\n",
      "\n",
      "Pearson Correlation: 0.1217\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.6052\n",
      "EdLevel NoHigherEd: 0.6119\n",
      "EdLevel Other: 0.5968\n",
      "EdLevel PhD: 0.5889\n",
      "EdLevel Undergraduate: 0.608\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Custom Evaluation ---\n",
    "evaluate_model(y_test_pmute, y_pred_lime_localmute)\n",
    "\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='EdLevel', label_name='EdLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.61\n",
      "1: TPR = 0.59\n",
      "2: TPR = 0.61\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Custom Fairness Functions ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')\n",
    "disparate_impact(df, 1, 0, 'Gender')\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_pmute.reset_index(drop=True),\n",
    "    pd.Series(y_pred_lime_localmute),\n",
    "    [0, 1, 2],\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
