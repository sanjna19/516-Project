{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = r\"C:\\Users\\asrit\\Documents\\516-Project-main\\516-Project-main\\src\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from data_loader import load_dataset\n",
    "from modeling import train_smote_forest, evaluate_model, train_random_forest\n",
    "from fairness_metrics import print_group_rates, disparate_impact, equal_opportunity\n",
    "from preprocess import apply_reweighing\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.metrics import MetricFrame, selection_rate\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_dataset(\"../data/cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 → Man\n",
      "1 → NonBinary\n",
      "2 → Woman\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"../data/cleaned_dataset.csv\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_original['Gender'])\n",
    "\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{i} → {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a preprocessing mitigation strategy - AIF360’s Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply AIF360 Reweighing (only used for fairness metrics, not for training if SMOTE is applied)\n",
    "df = apply_reweighing(df, protected_attr='Gender', label_col='Employment')\n",
    "\n",
    "# Step 2: Feature engineering for modeling\n",
    "features = ['Gender_encoded', 'Age_encoded', 'EdLevel', 'YearsCode', 'YearsCodePro', 'ComputerSkills', 'PreviousSalary']\n",
    "X = pd.get_dummies(df[features], drop_first=True)\n",
    "y = df['Employment'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7463133536004356\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.25      0.19      2571\n",
      "           1       0.89      0.81      0.85     19468\n",
      "\n",
      "    accuracy                           0.75     22039\n",
      "   macro avg       0.52      0.53      0.52     22039\n",
      "weighted avg       0.81      0.75      0.77     22039\n",
      "\n",
      "Pearson Correlation: 0.0531\n",
      "Mean Absolute Error: 0.2537\n",
      "Accuracy for Gender 0: 0.7403\n",
      "Accuracy for Gender 1: 0.6706\n",
      "Accuracy for Gender 2: 0.8977\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Choose model strategy\n",
    "use_smote = True  # Toggle this to False to use reweighing instead of SMOTE\n",
    "\n",
    "if use_smote:\n",
    "    model, X_test, y_test, y_pred = train_smote_forest(X, y)\n",
    "else:\n",
    "    sample_weights = df['instance_weight']\n",
    "    model, X_test, y_test, y_pred = train_random_forest(X, y, sample_weights)\n",
    "\n",
    "# Step 4: Evaluate base model performance (before fairness post-processing)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n",
    "# --- 3. Equal Accuracy by Gender Group ---\n",
    "y_test_aligned = y_test.reset_index(drop=True)\n",
    "y_pred_aligned = pd.Series(y_pred).reset_index(drop=True)\n",
    "gender_column = df.loc[y_test.index, 'Gender_encoded'].reset_index(drop=True)\n",
    "\n",
    "# --- 1. Pearson's Correlation ---\n",
    "pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "print(f\"Pearson Correlation: {round(pearson_corr, 4)}\")\n",
    "\n",
    "# --- 2. Mean Absolute Error ---\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {round(mae, 4)}\")\n",
    "\n",
    "equal_accuracy = {}\n",
    "for group in sorted(gender_column.unique()):\n",
    "    group_mask = gender_column == group\n",
    "    acc = accuracy_score(y_test_aligned[group_mask], y_pred_aligned[group_mask])\n",
    "    equal_accuracy[group] = acc\n",
    "    print(f\"Accuracy for Gender {group}: {round(acc, 4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.81\n",
      "1: TPR = 0.82\n",
      "2: TPR = 0.78\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Custom fairness metrics based on fairness-aware predictions\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "# Disparate impact comparisons\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "# Equal opportunity using fairness-aware predictions\n",
    "equal_opportunity(\n",
    "    y_test.reset_index(drop=True),\n",
    "    pd.Series(y_pred), \n",
    "    [0, 1, 2],  # Man, NonBinary, Woman\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_consistent_metrics(y_test, y_pred, sensitive_col='Gender_encoded', label_name='Gender'):\n",
    "    \"\"\"\n",
    "    Evaluate predictions using MAE, Pearson correlation, and group-wise accuracy.\n",
    "    Assumes access to global df and X_test_pmute for index alignment.\n",
    "    \"\"\"\n",
    "    # Align predictions and labels\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "    \n",
    "    # Align sensitive attribute values from df using test indices\n",
    "    sensitive_series = df.loc[y_test.index, sensitive_col].reset_index(drop=True)\n",
    "\n",
    "    # --- 1. Pearson Correlation ---\n",
    "    pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "    print(f\"\\nPearson Correlation: {round(pearson_corr, 4)}\")\n",
    "\n",
    "    # --- 2. Mean Absolute Error ---\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {round(mae, 4)}\")\n",
    "\n",
    "    # --- 3. Group-wise Accuracy ---\n",
    "    print(f\"\\nAccuracy by {label_name} group:\")\n",
    "    for group in sorted(sensitive_series.unique()):\n",
    "        group_mask = sensitive_series == group\n",
    "        acc = accuracy_score(y_test[group_mask], y_pred[group_mask])\n",
    "        print(f\"{label_name} {group}: {round(acc, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient on SMOTE-balanced data:\n",
      "Accuracy: 0.6909569399700531\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.30      0.19      2571\n",
      "           1       0.89      0.74      0.81     19468\n",
      "\n",
      "    accuracy                           0.69     22039\n",
      "   macro avg       0.51      0.52      0.50     22039\n",
      "weighted avg       0.80      0.69      0.74     22039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Prepare data: remove sensitive feature from X, pass separately ---\n",
    "sensitive_feature_test = df.loc[X_test.index, \"Gender_encoded\"]\n",
    "sensitive_feature_train = df.loc[X.index.difference(X_test.index), \"Gender_encoded\"]\n",
    "\n",
    "X_train_eg = X.loc[X.index.difference(X_test.index)].drop(columns=[\"Gender_encoded\"])\n",
    "y_train_eg = y.loc[X.index.difference(X_test.index)]\n",
    "\n",
    "X_test_eg = X_test.drop(columns=[\"Gender_encoded\"])\n",
    "\n",
    "# --- 2. Train fairness-aware model ---\n",
    "eg_model = ExponentiatedGradient(\n",
    "    estimator=LogisticRegression(solver=\"liblinear\", class_weight='balanced'),\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01\n",
    ")\n",
    "eg_model.fit(X_train_eg, y_train_eg, sensitive_features=sensitive_feature_train)\n",
    "\n",
    "# --- 3. Predict ---\n",
    "y_pred_eg = eg_model.predict(X_test_eg)\n",
    "\n",
    "# --- 4. Evaluate performance ---\n",
    "print(\"Exponentiated Gradient on SMOTE-balanced data:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_eg))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_eg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6909569399700531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.30      0.19      2571\n",
      "           1       0.89      0.74      0.81     19468\n",
      "\n",
      "    accuracy                           0.69     22039\n",
      "   macro avg       0.51      0.52      0.50     22039\n",
      "weighted avg       0.80      0.69      0.74     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.032\n",
      "Mean Absolute Error: 0.309\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.6912\n",
      "Gender 1: 0.6489\n",
      "Gender 2: 0.7037\n",
      "\n",
      "Pearson Correlation: 0.032\n",
      "Mean Absolute Error: 0.309\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.6902\n",
      "Age 1: 0.6926\n",
      "\n",
      "Pearson Correlation: 0.032\n",
      "Mean Absolute Error: 0.309\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.6834\n",
      "EdLevel NoHigherEd: 0.6819\n",
      "EdLevel Other: 0.6846\n",
      "EdLevel PhD: 0.7041\n",
      "EdLevel Undergraduate: 0.6967\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Custom evaluation function (consistent with pre-processing) ---\n",
    "evaluate_model(y_test, y_pred_eg)\n",
    "\n",
    "# --- 6. Reusable consistency metrics: Pearson, MAE, group-wise accuracy ---\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test, y_pred_eg, sensitive_col='EdLevel', label_name='EdLevel')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.688893        0.736050\n",
      "1               0.710900        0.734597\n",
      "2               0.724172        0.763158\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.701553        0.746954\n",
      "1            0.671138        0.719198\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.695279        0.751788\n",
      "NoHigherEd     0.638356        0.714155\n",
      "Other          0.656463        0.711812\n",
      "PhD            0.677749        0.716113\n",
      "Undergraduate  0.704658        0.741090\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Group fairness metrics ---\n",
    "# Gender\n",
    "mf_eg_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=sensitive_feature_test\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender:\")\n",
    "print(mf_eg_gender.by_group)\n",
    "\n",
    "# Age\n",
    "mf_eg_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=df.loc[X_test.index, 'Age_encoded']\n",
    ")\n",
    "print(\"\\nFairness metrics by Age:\")\n",
    "print(mf_eg_age.by_group)\n",
    "\n",
    "# EdLevel\n",
    "mf_eg_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_eg,\n",
    "    sensitive_features=df.loc[X_test.index, 'EdLevel']\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel:\")\n",
    "print(mf_eg_edlevel.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.74\n",
      "1: TPR = 0.69\n",
      "2: TPR = 0.75\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Custom fairness functions ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test.reset_index(drop=True),\n",
    "    pd.Series(y_pred_eg),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ThresholdOptimizer(constraints=&#x27;equalized_odds&#x27;,\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ThresholdOptimizer</label><div class=\"sk-toggleable__content\"><pre>ThresholdOptimizer(constraints=&#x27;equalized_odds&#x27;,\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ThresholdOptimizer(constraints='equalized_odds',\n",
       "                   estimator=RandomForestClassifier(random_state=42),\n",
       "                   predict_method='predict_proba')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. 3-Way Split: Train (60%), Validation (10%), Test (30%) ---\n",
    "X_trainval, X_test_post, y_trainval, y_test_post = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train_post, X_val_post, y_train_post, y_val_post = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.125, stratify=y_trainval, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Apply SMOTE to training data ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_post_smote, y_train_post_smote = smote.fit_resample(X_train_post, y_train_post)\n",
    "\n",
    "# --- 3. Train classifier on SMOTE-balanced data ---\n",
    "model_post = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_post.fit(X_train_post_smote, y_train_post_smote)\n",
    "\n",
    "# --- 4. Apply ThresholdOptimizer using validation set ---\n",
    "sensitive_gender_val = df.loc[X_val_post.index, \"Gender_encoded\"]\n",
    "\n",
    "postprocessor = ThresholdOptimizer(\n",
    "    estimator=model_post,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "\n",
    "postprocessor.fit(\n",
    "    X_val_post,\n",
    "    y_val_post,\n",
    "    sensitive_features=sensitive_gender_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness-aware Evaluation (SMOTE + Equalized Odds):\n",
      "Overall Accuracy: 0.8688688234493398\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.06      0.10      2576\n",
      "           1       0.89      0.98      0.93     19463\n",
      "\n",
      "    accuracy                           0.87     22039\n",
      "   macro avg       0.57      0.52      0.52     22039\n",
      "weighted avg       0.81      0.87      0.83     22039\n",
      "\n",
      "Accuracy: 0.8688688234493398\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.06      0.10      2576\n",
      "           1       0.89      0.98      0.93     19463\n",
      "\n",
      "    accuracy                           0.87     22039\n",
      "   macro avg       0.57      0.52      0.52     22039\n",
      "weighted avg       0.81      0.87      0.83     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.0752\n",
      "Mean Absolute Error: 0.1311\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.8679\n",
      "Gender 1: 0.8511\n",
      "Gender 2: 0.9008\n",
      "\n",
      "Pearson Correlation: 0.0752\n",
      "Mean Absolute Error: 0.1311\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.8674\n",
      "Age 1: 0.8719\n",
      "\n",
      "Pearson Correlation: 0.0752\n",
      "Mean Absolute Error: 0.1311\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.8691\n",
      "EdLevel NoHigherEd: 0.8733\n",
      "EdLevel Other: 0.8738\n",
      "EdLevel PhD: 0.8848\n",
      "EdLevel Undergraduate: 0.8658\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Predict on test set ---\n",
    "sensitive_gender_test = df.loc[X_test_post.index, \"Gender_encoded\"]\n",
    "y_pred_fair = postprocessor.predict(\n",
    "    X_test_post,\n",
    "    sensitive_features=sensitive_gender_test\n",
    ")\n",
    "\n",
    "# --- 6. Evaluate overall performance ---\n",
    "print(\"\\nFairness-aware Evaluation (SMOTE + Equalized Odds):\")\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_test_post, y_pred_fair))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_post, y_pred_fair))\n",
    "\n",
    "# --- 7. Custom Evaluation ---\n",
    "evaluate_model(y_test_post, y_pred_fair)\n",
    "\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_post, y_pred_fair, sensitive_col='EdLevel', label_name='EdLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.867129        0.970241\n",
      "1               0.875895        0.980907\n",
      "2               0.901077        0.977473\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.891862        0.981813\n",
      "1            0.826879        0.950628\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.878386        0.981767\n",
      "NoHigherEd     0.791740        0.931459\n",
      "Other          0.798100        0.929534\n",
      "PhD            0.879423        0.982962\n",
      "Undergraduate  0.891759        0.980401\n"
     ]
    }
   ],
   "source": [
    "# --- 8. MetricFrame Fairness Evaluation ---\n",
    "mf_post_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=sensitive_gender_test\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender:\")\n",
    "print(mf_post_gender.by_group)\n",
    "\n",
    "mf_post_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=df.loc[X_test_post.index, 'Age_encoded']\n",
    ")\n",
    "print(\"\\nFairness metrics by Age:\")\n",
    "print(mf_post_age.by_group)\n",
    "\n",
    "mf_post_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_post,\n",
    "    y_pred=y_pred_fair,\n",
    "    sensitive_features=df.loc[X_test_post.index, 'EdLevel']\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel:\")\n",
    "print(mf_post_edlevel.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.97\n",
      "1: TPR = 0.98\n",
      "2: TPR = 0.99\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Custom Fairness Metrics ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_post.reset_index(drop=True),\n",
    "    pd.Series(y_pred_fair),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Proxy Mute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e37e93abb9a4d729de45cfc41105671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Train-Test Split ---\n",
    "X_train_pmute, X_test_pmute, y_train_pmute, y_test_pmute = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Train Base Model (Logistic Regression with Class Weights) ---\n",
    "lr_model_base = LogisticRegression(solver=\"liblinear\", class_weight='balanced')\n",
    "lr_model_base.fit(X_train_pmute, y_train_pmute)\n",
    "\n",
    "# --- 3. SHAP Explainability (KernelExplainer for probability output) ---\n",
    "explainer = shap.KernelExplainer(\n",
    "    lr_model_base.predict_proba,\n",
    "    X_train_pmute.sample(100, random_state=42)\n",
    ")\n",
    "shap_values = explainer.shap_values(X_test_pmute[:100])\n",
    "\n",
    "# --- 4. Mean Absolute SHAP Importance ---\n",
    "mean_abs_shap = np.abs(shap_values[1]).mean(axis=0)\n",
    "shap_summary = pd.DataFrame({\n",
    "    \"feature\": X_train_pmute.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProxyMute (Revised Proxy List):\n",
      "Accuracy: 0.6712645764326876\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.43      0.24      2576\n",
      "           1       0.90      0.70      0.79     19463\n",
      "\n",
      "    accuracy                           0.67     22039\n",
      "   macro avg       0.53      0.57      0.51     22039\n",
      "weighted avg       0.82      0.67      0.73     22039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Define Proxy Features to Mute (based on SHAP summary) ---\n",
    "proxy_features = ['PreviousSalary', 'EdLevel_Undergraduate', 'ComputerSkills']\n",
    "\n",
    "# --- 6. Muting Proxy Features in Test Set ---\n",
    "X_test_muted = X_test_pmute.copy()\n",
    "for col in proxy_features:\n",
    "    if col in X_test_muted.columns:\n",
    "        X_test_muted[col] = X_test_muted[col].mean()\n",
    "\n",
    "# --- 7. Predict on Muted Test Set ---\n",
    "y_pred_muted = lr_model_base.predict(X_test_muted)\n",
    "\n",
    "# --- 8. Performance Metrics ---\n",
    "print(\"ProxyMute (Revised Proxy List):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_pmute, y_pred_muted))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_pmute, y_pred_muted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness metrics by Gender (ProxyMute SHAP):\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.662799        0.676489\n",
      "1               0.763723        0.787589\n",
      "2               0.804114        0.860921\n",
      "\n",
      "Fairness metrics by Age (ProxyMute SHAP):\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.866442        0.949091\n",
      "1            0.314824        0.208771\n",
      "\n",
      "Fairness metrics by EdLevel (ProxyMute SHAP):\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.676226        0.681891\n",
      "NoHigherEd     0.601054        0.630053\n",
      "Other          0.543199        0.534314\n",
      "PhD            0.626474        0.609436\n",
      "Undergraduate  0.716169        0.745301\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Fairness Evaluation Using MetricFrame ---\n",
    "# Gender\n",
    "mf_shap_gender = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"Gender_encoded\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by Gender (ProxyMute SHAP):\")\n",
    "print(mf_shap_gender.by_group)\n",
    "\n",
    "# Age\n",
    "mf_shap_age = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"Age_encoded\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by Age (ProxyMute SHAP):\")\n",
    "print(mf_shap_age.by_group)\n",
    "\n",
    "# EdLevel\n",
    "mf_shap_edlevel = MetricFrame(\n",
    "    metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "    y_true=y_test_pmute,\n",
    "    y_pred=y_pred_muted,\n",
    "    sensitive_features=df.loc[X_test_pmute.index, \"EdLevel\"]\n",
    ")\n",
    "print(\"\\nFairness metrics by EdLevel (ProxyMute SHAP):\")\n",
    "print(mf_shap_edlevel.by_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6712645764326876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.43      0.24      2576\n",
      "           1       0.90      0.70      0.79     19463\n",
      "\n",
      "    accuracy                           0.67     22039\n",
      "   macro avg       0.53      0.57      0.51     22039\n",
      "weighted avg       0.82      0.67      0.73     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.0935\n",
      "Mean Absolute Error: 0.3287\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.6717\n",
      "Gender 1: 0.6277\n",
      "Gender 2: 0.6789\n",
      "\n",
      "Pearson Correlation: 0.0935\n",
      "Mean Absolute Error: 0.3287\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.67\n",
      "Age 1: 0.6739\n",
      "\n",
      "Pearson Correlation: 0.0935\n",
      "Mean Absolute Error: 0.3287\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.6662\n",
      "EdLevel NoHigherEd: 0.6667\n",
      "EdLevel Other: 0.6664\n",
      "EdLevel PhD: 0.6415\n",
      "EdLevel Undergraduate: 0.6776\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Consistent Utility Metrics ---\n",
    "evaluate_model(y_test_pmute, y_pred_muted)\n",
    "\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_muted, sensitive_col='EdLevel', label_name='EdLevel')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.70\n",
      "1: TPR = 0.66\n",
      "2: TPR = 0.70\n"
     ]
    }
   ],
   "source": [
    "# --- 11. Custom Fairness Metrics ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')  # Woman vs Man\n",
    "disparate_impact(df, 1, 0, 'Gender')  # NonBinary vs Man\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_pmute.reset_index(drop=True),\n",
    "    pd.Series(y_pred_muted),\n",
    "    [0, 1, 2],  # Gender groups\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Refined Proxy Mute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Initialize LIME Explainer ---\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_train_pmute.values,\n",
    "    feature_names=X_train_pmute.columns.tolist(),\n",
    "    class_names=[\"Not Employed\", \"Employed\"],\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=False\n",
    ")\n",
    "\n",
    "# --- 2. Local Muting: Top 2 Features per Instance ---\n",
    "X_test_localmute_muted = X_test_pmute.copy()\n",
    "\n",
    "for i in range(500):  # Apply LIME only to top 500 for speed\n",
    "    exp = explainer.explain_instance(\n",
    "        X_test_pmute.iloc[i].values,\n",
    "        lambda x: lr_model_base.predict_proba(pd.DataFrame(x, columns=X_train_pmute.columns)),\n",
    "        num_features=2\n",
    "    )\n",
    "    top_features = [f[0] for f in exp.as_list()]\n",
    "    \n",
    "    for f in top_features:\n",
    "        f_name = f.split('<')[0].split('>')[0].split('=')[0].strip()\n",
    "        if f_name in X_test_localmute_muted.columns:\n",
    "            col_idx = X_test_localmute_muted.columns.get_loc(f_name)\n",
    "            mean_val = X_train_pmute[f_name].mean()\n",
    "            col_dtype = X_test_localmute_muted.dtypes[f_name]\n",
    "            X_test_localmute_muted.iat[i, col_idx] = col_dtype.type(mean_val)\n",
    "\n",
    "# --- 3. Predict ---\n",
    "y_pred_lime_localmute = lr_model_base.predict(X_test_localmute_muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined ProxyMute (LIME, Top 2 Features):\n",
      "Accuracy: 0.6051544988429602\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.58      0.25      2576\n",
      "           1       0.92      0.61      0.73     19463\n",
      "\n",
      "    accuracy                           0.61     22039\n",
      "   macro avg       0.54      0.59      0.49     22039\n",
      "weighted avg       0.83      0.61      0.68     22039\n",
      "\n",
      "\n",
      "Fairness metrics by Gender:\n",
      "                accuracy  selection_rate\n",
      "Gender_encoded                          \n",
      "0               0.595709        0.575222\n",
      "1               0.644391        0.653938\n",
      "2               0.779628        0.795299\n",
      "\n",
      "Fairness metrics by Age:\n",
      "             accuracy  selection_rate\n",
      "Age_encoded                          \n",
      "0            0.700162        0.711607\n",
      "1            0.431649        0.359195\n",
      "\n",
      "Fairness metrics by EdLevel:\n",
      "               accuracy  selection_rate\n",
      "EdLevel                                \n",
      "Master         0.473889        0.428217\n",
      "NoHigherEd     0.308436        0.149385\n",
      "Other          0.291667        0.165748\n",
      "PhD            0.564875        0.505898\n",
      "Undergraduate  0.795189        0.839109\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Performance Metrics ---\n",
    "print(\"Refined ProxyMute (LIME, Top 2 Features):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_pmute, y_pred_lime_localmute))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_pmute, y_pred_lime_localmute))\n",
    "\n",
    "# --- 5. Fairness: MetricFrame by Group ---\n",
    "for attr, label in [(\"Gender_encoded\", \"Gender\"), (\"Age_encoded\", \"Age\"), (\"EdLevel\", \"EdLevel\")]:\n",
    "    mf = MetricFrame(\n",
    "        metrics={\"accuracy\": accuracy_score, \"selection_rate\": selection_rate},\n",
    "        y_true=y_test_pmute,\n",
    "        y_pred=y_pred_lime_localmute,\n",
    "        sensitive_features=df.loc[X_test_pmute.index, attr]\n",
    "    )\n",
    "    print(f\"\\nFairness metrics by {label}:\")\n",
    "    print(mf.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6051544988429602\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.58      0.25      2576\n",
      "           1       0.92      0.61      0.73     19463\n",
      "\n",
      "    accuracy                           0.61     22039\n",
      "   macro avg       0.54      0.59      0.49     22039\n",
      "weighted avg       0.83      0.61      0.68     22039\n",
      "\n",
      "\n",
      "Pearson Correlation: 0.1219\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by Gender group:\n",
      "Gender 0: 0.6054\n",
      "Gender 1: 0.5851\n",
      "Gender 2: 0.6068\n",
      "\n",
      "Pearson Correlation: 0.1219\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by Age group:\n",
      "Age 0: 0.6041\n",
      "Age 1: 0.6074\n",
      "\n",
      "Pearson Correlation: 0.1219\n",
      "Mean Absolute Error: 0.3948\n",
      "\n",
      "Accuracy by EdLevel group:\n",
      "EdLevel Master: 0.6063\n",
      "EdLevel NoHigherEd: 0.6155\n",
      "EdLevel Other: 0.5942\n",
      "EdLevel PhD: 0.5917\n",
      "EdLevel Undergraduate: 0.6077\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Custom Evaluation ---\n",
    "evaluate_model(y_test_pmute, y_pred_lime_localmute)\n",
    "\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='Gender_encoded', label_name='Gender')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='Age_encoded', label_name='Age')\n",
    "run_consistent_metrics(y_test_pmute, y_pred_lime_localmute, sensitive_col='EdLevel', label_name='EdLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Rates by Gender:\n",
      "0: 0.88\n",
      "2: 0.91\n",
      "1: 0.87\n",
      "\n",
      "Selection Rates by Age:\n",
      "<35: 0.90\n",
      ">35: 0.85\n",
      "\n",
      "Selection Rates by EdLevel:\n",
      "Master: 0.88\n",
      "Undergraduate: 0.90\n",
      "PhD: 0.90\n",
      "Other: 0.84\n",
      "NoHigherEd: 0.80\n",
      "\n",
      "Disparate Impact (2/0): 1.03\n",
      "\n",
      "Disparate Impact (1/0): 0.98\n",
      "\n",
      "Disparate Impact (>35/<35): 0.95\n",
      "\n",
      "Equal Opportunity by group:\n",
      "0: TPR = 0.61\n",
      "1: TPR = 0.59\n",
      "2: TPR = 0.61\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Custom Fairness Functions ---\n",
    "print_group_rates(df, 'Gender')\n",
    "print_group_rates(df, 'Age')\n",
    "print_group_rates(df, 'EdLevel')\n",
    "\n",
    "disparate_impact(df, 2, 0, 'Gender')\n",
    "disparate_impact(df, 1, 0, 'Gender')\n",
    "disparate_impact(df, '>35', '<35', 'Age')\n",
    "\n",
    "equal_opportunity(\n",
    "    y_test_pmute.reset_index(drop=True),\n",
    "    pd.Series(y_pred_lime_localmute),\n",
    "    [0, 1, 2],\n",
    "    'Gender',\n",
    "    df.reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
